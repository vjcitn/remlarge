---
title: "remlarge"
author: 
  - Vince Carey^[stvjc@channing.harvard.edu]
vignette: >
  %\VignetteIndexEntry{Working with remote large data in Bioconductor}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
output: 
  BiocStyle::html_document:
    number_sections: yes
    theme: united
    toc: yes
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(BiocStyle)
```

# Introduction

This vignette reviews basic aspects of using Bioconductor with
remote data services for very large data.  We'll consider how to

- access HDF5 directly from AWS S3 buckets using rhdf5
- use a RESTful API to interrogate HDF5 in the HDF Scalable Data Service
- wrap Google BigQuery tables in SummarizedExperiment instances
- work with TileDb data resources
